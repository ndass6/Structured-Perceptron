{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Set 3: Structured Perceptron\n",
    "====================\n",
    "\n",
    "In this problem set, you will implement a sequence labeling algorithm that is near state-of-the-art: structured perceptron. To do this, you will use several functions that you have written earlier, especially Viterbi and averaged perceptron.\n",
    "\n",
    "The problem set is designed to highlight the connection between structured perceptron and classification-based tagging. You will first write most of the pieces that you need while working in the framework of classification-based tagging. Your implementation will take various tagging algorithms as arguments, including both one-word-at-a-time classification based tagging, and Viterbi sequence labeling.\n",
    "\n",
    "One of the main reasons to prefer perceptron over hidden Markov models is the ability to use rich, overlapping features. You will design several feature functions throughout the assignment.\n",
    "\n",
    "Because structure perceptron is slower to train than the hidden Markov model, we will use smaller datasets in this assignment, focusing on sentences that contain the most common POS tags in English and Japanese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gtnlplib import preproc, tagger_base, scorer \n",
    "from gtnlplib import features, viterbi, constants, structure_perceptron, kaggle\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English tags: set([u'ADV', u'NOUN', u'ADP', u'PRON', u'PROPN', u'DET', u'PUNCT', u'VERB', u'AUX', u'ADJ'])\n",
      "Japanese tags: set([u'ADV', u'NOUN', u'PRON', u'DET', u'PUNCT', u'VERB', u'NUM', u'ADJ'])\n"
     ]
    }
   ],
   "source": [
    "## Demo\n",
    "## NOTE! These datafiles are different than in pset2. Don't copy over constants.py from that pset.\n",
    "all_tags = set()\n",
    "for i,(words, tags) in enumerate(preproc.conll_seq_generator(constants.TRAIN_FILE,max_insts=100000)):\n",
    "    for tag in tags:\n",
    "        all_tags.add(tag)\n",
    "print(\"English tags: {}\".format(all_tags))\n",
    "\n",
    "all_tags_ja = set()\n",
    "for i,(words, tags) in enumerate(preproc.conll_seq_generator(constants.JA_TRAIN_FILE,max_insts=100000)):\n",
    "    for tag in tags:\n",
    "        all_tags_ja.add(tag)\n",
    "print(\"Japanese tags: {}\".format(all_tags_ja))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tagging as discriminative classification\n",
    "\n",
    "In pset 2, you performed part-of-speech tagging as generative classification, using Naive Bayes. Now you will perform discriminative classification, using average perceptron.\n",
    "\n",
    "In this section, we are only doing classification-based tagging, but we will write the code in a way that generalizes to Viterbi-based structure prediction. This means that all features are of the form $f(\\boldsymbol{w},y_m,y_{m-1},m)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.1** Implement `features.word_feats` to output features that are tuples `(y,constants.CURR_WORD_FEAT,w[m])` and `(y,constants.OFFSET)`.\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('NOUN', '**OFFSET**'): 1, ('NOUN', '--CURR-WORD--', 'man'): 1}\n",
      "{('VERB', '--CURR-WORD--', 'the'): 1, ('VERB', '**OFFSET**'): 1}\n",
      "{('NOUN', '**OFFSET**'): 1}\n"
     ]
    }
   ],
   "source": [
    "print(features.word_feats(['The','old','man','the','boat'],'NOUN','ADJ',2))\n",
    "print(features.word_feats(['The','old','man','the','boat'],'VERB','NOUN',3))\n",
    "# note that we may need to handle m >= len(tokens)\n",
    "print(features.word_feats(['The','old','man','the','boat'],'NOUN','ADJ',5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.2** Reimplement `tagger_base.classifier_tagger` as follows:\n",
    "\n",
    "Inputs:\n",
    "\n",
    "- List of tokens to tag\n",
    "- Feature function, of the form $f(\\boldsymbol{w},y_m,y_{m-1},m)$\n",
    "- Defaultdict of weights\n",
    "- List of all candidate tags\n",
    "\n",
    "Outputs:\n",
    "\n",
    "- List of predicted tags\n",
    "- Score of predicted tag sequence $\\theta \\cdot f(\\boldsymbol{w},\\boldsymbol{y})$\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_clf_hand = defaultdict(float,\n",
    "                             {('NOUN',constants.OFFSET):0.1,\n",
    "                              ('PRON',constants.CURR_WORD_FEAT,'They'):1,\n",
    "                              ('PRON',constants.CURR_WORD_FEAT,'can'):-1,\n",
    "                              ('NOUN',constants.CURR_WORD_FEAT,'fish'):1,\n",
    "                              ('VERB',constants.CURR_WORD_FEAT,'fish'):0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['They', 'can', 'fish']\n"
     ]
    }
   ],
   "source": [
    "w = 'They can fish'.split()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(tagger_base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'PRON', u'NOUN', u'NOUN'], 2.2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.classifier_tagger(w,features.word_feats,theta_clf_hand,all_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.3** The perceptron update requires computing the difference\n",
    "\n",
    "\\begin{align}\n",
    "& f(\\boldsymbol{w},\\boldsymbol{y}) - f(\\boldsymbol{w},\\hat{\\boldsymbol{y}})\\\\\n",
    "= & \\sum_{m=1}^M f(\\boldsymbol{w},y_m,y_{m-1},m) - f(\\boldsymbol{w},\\hat{y}_m,\\hat{y}_{m-1},m)\n",
    "\\end{align}\n",
    "\n",
    "Implement `tagger_base.compute_features` to compute $f(\\boldsymbol{w},\\boldsymbol{y})$, with the following arguments:\n",
    "\n",
    "- A list of words\n",
    "- A list of tags\n",
    "- A feature function, of the form $f(\\boldsymbol{w},y_m,y_{m-1},m)$.\n",
    "\n",
    "The output should be a dict of features and counts.\n",
    "\n",
    "*Boundary cases*: \n",
    "\n",
    "- When $m=0$, use the special case $y_{-1} = \\text{START}$, using `constants.START_TAG`. *Your current feature function will not test this, because it ignores $y_{m-1}$, but we will test it later*.\n",
    "- When $m=M$, use the special case $y_M = \\text{STOP}$, using `constants.END_TAG`. \n",
    "\n",
    "These boundary cases will be important when you incorporate Viterbi tagging.\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(tagger_base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {('--END--', '**OFFSET**'): 1.0,\n",
       "             ('DET', '**OFFSET**'): 2.0,\n",
       "             ('DET', '--CURR-WORD--', 'the'): 2.0,\n",
       "             ('NOUN', '**OFFSET**'): 2.0,\n",
       "             ('NOUN', '--CURR-WORD--', 'boat'): 1.0,\n",
       "             ('NOUN', '--CURR-WORD--', 'old'): 1.0,\n",
       "             ('VERB', '**OFFSET**'): 1.0,\n",
       "             ('VERB', '--CURR-WORD--', 'man'): 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.compute_features('the old man the boat'.split(),\n",
    "                            ['DET','NOUN','VERB','DET','NOUN'],\n",
    "                            features.word_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.4**\n",
    "\n",
    "Now you can implement the function `structure_perceptron.sp_update`. \n",
    "\n",
    "This will be very similar to your implementation of `perceptron.perceptron_update` in pset 1, but instead of calling `clf_base.predict`, you should call a function `tagger` which is passed in as an argument.\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(structure_perceptron);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'PRON', u'NOUN', u'NOUN'], 2.2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.classifier_tagger('They can fish'.split(),\n",
    "                             features.word_feats,\n",
    "                             theta_clf_hand,\n",
    "                             all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update = structure_perceptron.sp_update('They can fish'.split(),\n",
    "                               ['PRON','AUX','VERB'],\n",
    "                               theta_clf_hand,\n",
    "                               features.word_feats,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'NOUN', '--CURR-WORD--', 'fish'), -1.0)\n",
      "((u'NOUN', '**OFFSET**'), -2.0)\n",
      "(('AUX', '--CURR-WORD--', 'can'), 1.0)\n",
      "(('VERB', '--CURR-WORD--', 'fish'), 1.0)\n",
      "(('VERB', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'can'), -1.0)\n",
      "(('AUX', '**OFFSET**'), 1.0)\n"
     ]
    }
   ],
   "source": [
    "for key,val in update.iteritems():\n",
    "    if val != 0:\n",
    "        print(key,val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.5**\n",
    "\n",
    "You are now ready to implement `structure_perceptron.estimate_perceptron`.\n",
    "\n",
    "Your implementation will be nearly identical to `perceptron.estimate_perceptron`, except for two things:\n",
    "\n",
    "- The input is now a list of (token-list, tag-list) tuples\n",
    "- Instead of calling `perceptron.perceptron_update`, you will call `structure_perceptron.sp_update`.\n",
    "\n",
    "Other aspects of the implementation, such as weight averaging, should be identical.\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features)\n",
    "reload(tagger_base)\n",
    "reload(structure_perceptron);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toy_data = [('They can fish'.split(),['PRON','AUX','VERB']),\n",
    "            ('the old man the boat'.split(),['DET','NOUN','VERB','DET','NOUN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "theta_toy_one_inst,_ = structure_perceptron.estimate_perceptron(toy_data[:1],\n",
    "                                                                features.word_feats,\n",
    "                                                                tagger_base.classifier_tagger,\n",
    "                                                                1,\n",
    "                                                                all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('NOUN', '**OFFSET**'): 1, ('NOUN', '--CURR-WORD--', 'They'): 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.word_feats(toy_data[0][0],'NOUN','IGNORE',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'PRON', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'can'), -1.0)\n",
      "((u'AUX', '--CURR-WORD--', 'can'), 1.0)\n",
      "((u'VERB', '--CURR-WORD--', 'fish'), 1.0)\n",
      "((u'VERB', '**OFFSET**'), 1.0)\n",
      "(('NOUN', '**OFFSET**'), -2.999)\n",
      "((u'NOUN', '--CURR-WORD--', 'They'), -1.0)\n",
      "((u'AUX', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'fish'), -1.0)\n",
      "((u'PRON', '--CURR-WORD--', 'They'), 1.0)\n"
     ]
    }
   ],
   "source": [
    "for feat,weight in theta_toy_one_inst.iteritems():\n",
    "    if weight != 0:\n",
    "        print(feat,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9\n"
     ]
    }
   ],
   "source": [
    "theta_toy_one_inst,_ = structure_perceptron.estimate_perceptron(toy_data[:1],\n",
    "                                                                features.word_feats,\n",
    "                                                                tagger_base.classifier_tagger,\n",
    "                                                                10,\n",
    "                                                                all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'PRON', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'can'), -1.0)\n",
      "((u'AUX', '--CURR-WORD--', 'can'), 1.0)\n",
      "((u'VERB', '--CURR-WORD--', 'fish'), 1.0)\n",
      "((u'VERB', '**OFFSET**'), 1.0)\n",
      "(('NOUN', '**OFFSET**'), -2.999)\n",
      "((u'NOUN', '--CURR-WORD--', 'They'), -1.0)\n",
      "((u'AUX', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'fish'), -1.0)\n",
      "((u'PRON', '--CURR-WORD--', 'They'), 1.0)\n"
     ]
    }
   ],
   "source": [
    "for feat,weight in theta_toy_one_inst.iteritems():\n",
    "    if weight != 0:\n",
    "        print(feat,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "theta_toy,_ = structure_perceptron.estimate_perceptron(toy_data,\n",
    "                                                     features.word_feats,\n",
    "                                                     tagger_base.classifier_tagger,\n",
    "                                                     1, all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'PRON', '--CURR-WORD--', 'man'), -0.5)\n",
      "((u'PRON', '**OFFSET**'), -1.5)\n",
      "((u'NOUN', '--CURR-WORD--', 'can'), -1.0)\n",
      "((u'PRON', '--CURR-WORD--', 'the'), -1.0)\n",
      "((u'PRON', '--CURR-WORD--', 'old'), -0.5)\n",
      "((u'VERB', '--CURR-WORD--', 'man'), 0.5)\n",
      "((u'AUX', '--CURR-WORD--', 'can'), 1.0)\n",
      "((u'VERB', '--CURR-WORD--', 'fish'), 1.0)\n",
      "((u'VERB', '**OFFSET**'), 1.5)\n",
      "((u'PRON', '--CURR-WORD--', 'boat'), -0.5)\n",
      "((u'PRON', '--CURR-WORD--', 'They'), 1.0)\n",
      "(('NOUN', '**OFFSET**'), -1.999)\n",
      "((u'NOUN', '--CURR-WORD--', 'old'), 0.5)\n",
      "((u'AUX', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'fish'), -1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'boat'), 0.5)\n",
      "((u'DET', '**OFFSET**'), 1.0)\n",
      "((u'DET', '--CURR-WORD--', 'the'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'They'), -1.0)\n"
     ]
    }
   ],
   "source": [
    "for feat,weight in theta_toy.iteritems():\n",
    "    if weight != 0:\n",
    "        print(feat,weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverable 1.6 ** Let's train this tagger and evaluate it.\n",
    "\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = [inst for inst in preproc.conll_seq_generator(constants.TRAIN_FILE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3531"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes 30 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n"
     ]
    }
   ],
   "source": [
    "theta_avp,theta_hist = structure_perceptron.estimate_perceptron(training_set,\n",
    "                                                       features.word_feats,\n",
    "                                                       tagger_base.classifier_tagger,\n",
    "                                                       20,\n",
    "                                                       all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8129496402877698"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-te.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-020d7712d1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# you can't run this line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'avp-words-te.preds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Success\\OneDrive\\Documents\\Georgia Tech\\Junior Year\\Spring 2017\\CS 4650\\Problem Set 3\\gtnlplib\\scorer.pyc\u001b[0m in \u001b[0;36mget_confusion\u001b[0;34m(keyfilename, responsefilename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsefilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'"
     ]
    }
   ],
   "source": [
    "# you can't run this line\n",
    "scorer.accuracy(scorer.get_confusion(constants.TEST_FILE,'avp-words-te.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how accuracy improved over training. \n",
    "You can use this function elsewhere in the notebook if you'd like to see the progress of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOsQtkrflQYkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe431d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tagger_base.plot_learning_curve(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_hist,\n",
    "                               all_tags);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These accuracies are not directly comparable with your HMM accuracies from pset2, since we are using a different dataset.\n",
    "\n",
    "Let's see how many features are active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of active features: 19265\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of active features: %d\"%len([val for val in theta_avp.values() if val != 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.7** Now try it on Japanese. \n",
    "\n",
    "(*0.5 points for 4650 / 0.25 points for 7650*)\n",
    "\n",
    "As before, 4650 students can opt in to 7650 grading by doing the 7650 problems.\n",
    "\n",
    "Please set the `GRADING` variable in `constants.py` to the appropriate grading scheme. Note that CS7650 students must be graded by the CS7650 rubric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_ja = [inst for inst in preproc.conll_seq_generator(constants.JA_TRAIN_FILE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes approximately 40 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n"
     ]
    }
   ],
   "source": [
    "theta_avp_ja,theta_hist_ja =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.word_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.790288213524728"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.JA_TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-te.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/ja-ud-simpler-test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-7dcf2e65eed1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# you can't run this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJA_TEST_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'avp-words-te.ja.preds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Success\\OneDrive\\Documents\\Georgia Tech\\Junior Year\\Spring 2017\\CS 4650\\Problem Set 3\\gtnlplib\\scorer.pyc\u001b[0m in \u001b[0;36mget_confusion\u001b[0;34m(keyfilename, responsefilename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsefilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/ja-ud-simpler-test.conllu'"
     ]
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.JA_TEST_FILE,'avp-words-te.ja.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.8 (for 7650)** As you can see from the cells here, this tagging model is less accurate for Japanese than it is for English. Why might that be? (I'm looking for an explanation that is based on quantitative facts about the datasets.) Put your answer in `text-answers.md`.\n",
    "\n",
    "(*0.5 points for 7650, optional for 4650*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Better features\n",
    "\n",
    "One simple way to improve tagging is to add better features to the classification-based tagger. \n",
    "\n",
    "**Deliverable 2.1** Let's start by adding features that include the final two characters of each word as an additional, suffix feature. Do this by implementing `word_suff_features` in `features.py`.\n",
    "\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(constants)\n",
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('DET', '--CURR-WORD--', 'The'): 1, ('DET', '**OFFSET**'): 1, ('DET', '--SUFFIX--', 'he'): 1}\n",
      "{('NOUN', '--SUFFIX--', 'ld'): 1, ('NOUN', '**OFFSET**'): 1, ('NOUN', '--CURR-WORD--', 'old'): 1}\n",
      "{('NOUN', '**OFFSET**'): 1, ('NOUN', '--SUFFIX--', 'a'): 1, ('NOUN', '--CURR-WORD--', 'a'): 1}\n"
     ]
    }
   ],
   "source": [
    "print(features.word_suff_feats(['The','old','man','a','boat'],'DET','ADJ',0))\n",
    "print(features.word_suff_feats(['The','old','man','a','boat'],'NOUN','DET',1))\n",
    "print(features.word_suff_feats(['The','old','man','a','boat'],'NOUN','ADJ',3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.2** Let's see whether this improves accuracy.\n",
    "\n",
    "(*0.5 points for 4650, 0.25 points for 7650. Includes both English and Japanese evaluations.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes 50 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n"
     ]
    }
   ],
   "source": [
    "theta_suff_avp,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.word_suff_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8439248601119105"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_suff_feats,\n",
    "                               theta_suff_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-suff.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_suff_feats,\n",
    "                               theta_suff_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-suff-te.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-0c0f5fa3ae5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# you cannot run this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'avp-words-suff-te.preds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Success\\OneDrive\\Documents\\Georgia Tech\\Junior Year\\Spring 2017\\CS 4650\\Problem Set 3\\gtnlplib\\scorer.pyc\u001b[0m in \u001b[0;36mget_confusion\u001b[0;34m(keyfilename, responsefilename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsefilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'"
     ]
    }
   ],
   "source": [
    "# you cannot run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.TEST_FILE,'avp-words-suff-te.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is 3% better than the word-only feature set! That's pretty good for adding a single feature template. Now let's try Japanese. \n",
    "\n",
    "The cell below takes 45 seconds to execute on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n"
     ]
    }
   ],
   "source": [
    "theta_suff_avp_ja,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.word_suff_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8816866659190311"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_suff_feats,\n",
    "                               theta_suff_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-suff.ja.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10% better on Japanese! Why might that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.JA_TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_suff_feats,\n",
    "                               theta_suff_avp_ja,\n",
    "                               all_tags,\n",
    "                               'avp-words-suff-te.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/ja-ud-simpler-test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-129fe741bb06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# you can't run this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJA_TEST_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'avp-words-suff-te.ja.preds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Success\\OneDrive\\Documents\\Georgia Tech\\Junior Year\\Spring 2017\\CS 4650\\Problem Set 3\\gtnlplib\\scorer.pyc\u001b[0m in \u001b[0;36mget_confusion\u001b[0;34m(keyfilename, responsefilename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsefilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/ja-ud-simpler-test.conllu'"
     ]
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.JA_TEST_FILE,'avp-words-suff-te.ja.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.3 (7650)** Briefly explain why you think suffix features are so helpful in Japanese. No prior Japanese knowledge is assumed! You may want to look at the raw data, and consult some resources about Japanese that you can find from a quick Google search. Put your answer in `text-answers.md`.\n",
    "\n",
    "(*0.5 points for 7650, optional for 4650*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.4** Now implement word neighbor features. These are features that should link a given tag to the words than come before and after it. Implement this function in `features.word_neighbor_feats`, and make sure it gives the same results as in the example cell below. Pay attention to the boundary case at the end. See `constants.PRE_START_TOKEN` and `constants.POST_END_TOKEN`.\n",
    "\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(constants)\n",
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TAG', '--CURR-WORD--', 'The'): 1\n",
      "('TAG', '**OFFSET**'): 1\n",
      "('TAG', '--PREV-WORD--', '[[START]]'): 1\n",
      "('TAG', '--NEXT-WORD--', 'old'): 1\n",
      "\n",
      "('TAG', '**OFFSET**'): 1\n",
      "('TAG', '--NEXT-WORD--', 'man'): 1\n",
      "('TAG', '--PREV-WORD--', 'The'): 1\n",
      "('TAG', '--CURR-WORD--', 'old'): 1\n",
      "\n",
      "('TAG', '**OFFSET**'): 1\n",
      "('TAG', '--NEXT-WORD--', 'a'): 1\n",
      "('TAG', '--CURR-WORD--', 'man'): 1\n",
      "('TAG', '--PREV-WORD--', 'old'): 1\n",
      "\n",
      "('TAG', '**OFFSET**'): 1\n",
      "('TAG', '--CURR-WORD--', 'a'): 1\n",
      "('TAG', '--PREV-WORD--', 'man'): 1\n",
      "('TAG', '--NEXT-WORD--', 'boat'): 1\n",
      "\n",
      "('TAG', '**OFFSET**'): 1\n",
      "('TAG', '--NEXT-WORD--', '[[END]]'): 1\n",
      "('TAG', '--PREV-WORD--', 'a'): 1\n",
      "('TAG', '--CURR-WORD--', 'boat'): 1\n",
      "\n",
      "('TAG', '**OFFSET**'): 1\n",
      "('TAG', '--PREV-WORD--', 'boat'): 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in xrange(6):\n",
    "    feats = features.word_neighbor_feats(['The','old','man','a','boat'],'TAG','IGNORE',m)\n",
    "    for feat,count in feats.iteritems():\n",
    "        print('{}: {}'.format(feat,count))\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.5** Let's try it, in both English and Japanese.\n",
    "\n",
    "(*0.5 points for 4650, 0.25 points for 7650*)\n",
    "\n",
    "The code below takes 60 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n"
     ]
    }
   ],
   "source": [
    "theta_neighbor_avp,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.word_neighbor_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8577138289368506"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_neighbor_feats,\n",
    "                               theta_neighbor_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-neighbor.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better for English than the suffix features! Let's try Japanese.\n",
    "\n",
    "The code below takes 60 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n"
     ]
    }
   ],
   "source": [
    "theta_neighbor_avp_ja,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.word_neighbor_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8020634742626443"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_neighbor_feats,\n",
    "                               theta_neighbor_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-neighbor.ja.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neighbor features don't help nearly as much in Japanese, compared to the impact they make in English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAKEOFF #1\n",
    "\n",
    "**Deliverable 2.6** Implement the best features that you can for English and Japanese.\n",
    "You can use the same features for each, or you can use different features.\n",
    "You can also train the model longer, if you think that will help.\n",
    "\n",
    "Make sure to save the output in the following files:\n",
    "\n",
    "- **English dev**: `avp-best.preds`\n",
    "- **English test**: `avp-best-te.preds`\n",
    "- **Japanese dev**: `avp-best.ja.preds`\n",
    "- **Japanese test**: `avp-best-te.ja.preds`\n",
    "\n",
    "Grading:\n",
    "- Full credit (0.5 pts) for **88%** accuracy on English dev set, half credit (0.25 pts) for **87%** dev set accuracy.\n",
    "- Full credit (0.5 pts) for **90%** accuracy on Japanese dev set, half credit (0.25 pts) for **89%** dev set accuracy.\n",
    "- +0.1 for beating my test set score on English\n",
    "- +0.1 for beating my test set score on Japanese\n",
    "- +0.2 for top English score in 4650\n",
    "- +0.2 for top English score in 7650\n",
    "- +0.2 for top Japanese score in 4650\n",
    "- +0.2 for top Japanese score in 7650\n",
    "\n",
    "If you want to use an external library that is not standard with Python, please ask. For this part of the assignment, we will be more open to the use of 3rd party code, as long as it can be incorporated into your feature function. Libraries that include models that were trained on POS-labeled data will not be allowed. **We must be able to run your code to regenerate your outputs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started With Kaggle\n",
    "In this bakeoff and the one at the end of this problem set, you will submit your results on the test data to Kaggle, which will keep an updated leaderboard of the best taggers in the class.\n",
    "\n",
    "Above each code snippet that outputs a file that you need to submit to Kaggle will be a link inviting you to the competition.  *NOTE THERE ARE 4 SEPARATE COMPETITIONS*, one for each combo of English and Japanese with AVP and Structure Prediction.  Make sure to submit the correct file to the correct competition.\n",
    "\n",
    "Your Kaggle account needs to be registered with an @gatech.edu email to join.  Also, please make your display name your real name.\n",
    "\n",
    "The public leaderboard shows how your taggers compare to your classmates on 50% of the test data.  The final standings on 100% of the test data will be released after the competition is over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n"
     ]
    }
   ],
   "source": [
    "# for my best classification-based tagger, I trained the model for 30 iterations\n",
    "# this took a few minutes\n",
    "theta_best_avp,theta_best_avp_hist =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.word_feats_competitive_en,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         30,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n",
      "0.887090327738\n"
     ]
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_en,\n",
    "                               theta_best_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-best.preds')\n",
    "print(dev_results)\n",
    "tagger_base.apply_tagging_model(constants.TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_en,\n",
    "                               theta_best_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-best-te.preds')\n",
    "\n",
    "# SUBMIT KAGGLE-avp-bakeoff1-en-test.csv TO https://kaggle.com/join/gtclassificationtaggingen\n",
    "kaggle.kaggle_output(constants.TEST_FILE_HIDDEN,\n",
    "                                tagger_base.classifier_tagger,\n",
    "                                features.word_feats_competitive_en,\n",
    "                                theta_best_avp,\n",
    "                                all_tags,\n",
    "                                'KAGGLE-avp-bakeoff1-en-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c088dab9f753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# you can't run this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'avp-words-best-te.preds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Success\\OneDrive\\Documents\\Georgia Tech\\Junior Year\\Spring 2017\\CS 4650\\Problem Set 3\\gtnlplib\\scorer.pyc\u001b[0m in \u001b[0;36mget_confusion\u001b[0;34m(keyfilename, responsefilename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsefilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'"
     ]
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.TEST_FILE,'avp-words-best-te.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n"
     ]
    }
   ],
   "source": [
    "theta_best_avp_ja,theta_best_avp_hist_ja =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.word_feats_competitive_ja,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         30,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1084db00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# as you can see, in this case there was little advantage to training past ten iterations\n",
    "tagger_base.plot_learning_curve(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_ja,\n",
    "                               theta_best_avp_hist_ja,\n",
    "                               all_tags_ja);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n",
      "0.926656947404\n"
     ]
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_ja,\n",
    "                               theta_best_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-best.ja.preds')\n",
    "print(dev_results)\n",
    "tagger_base.apply_tagging_model(constants.JA_TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_ja,\n",
    "                               theta_best_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-best-te.ja.preds')\n",
    "\n",
    "# SUBMIT KAGGLE-avp-bakeoff1-ja-test.csv TO: https://kaggle.com/join/gtclassificationtaggingja\n",
    "kaggle.kaggle_output(constants.JA_TEST_FILE_HIDDEN,\n",
    "                                tagger_base.classifier_tagger,\n",
    "                                features.word_feats_competitive_ja,\n",
    "                                theta_best_avp_ja,\n",
    "                                all_tags_ja,\n",
    "                                'KAGGLE-avp-bakeoff1-ja-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/ja-ud-simpler-test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-9c0938c9cbaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# you can't run this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJA_TEST_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'avp-words-best-te.ja.preds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Success\\OneDrive\\Documents\\Georgia Tech\\Junior Year\\Spring 2017\\CS 4650\\Problem Set 3\\gtnlplib\\scorer.pyc\u001b[0m in \u001b[0;36mget_confusion\u001b[0;34m(keyfilename, responsefilename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsefilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/ja-ud-simpler-test.conllu'"
     ]
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.JA_TEST_FILE,'avp-words-best-te.ja.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Structure prediction\n",
    "\n",
    "We now want to incorporate the Viterbi algorithm into the part of speech tagger.\n",
    "\n",
    "If you completed problem set 2, you can do this directly: just replace `tagger_base.classifier_tagger` with `viterbi.viterbi_tagger`. If the feature sets don't use any tag-transition features, then the outputs should be exactly the same.\n",
    "\n",
    "**Deliverable 3.1** Verify that this works, using `features.word_feats`. If your code from pset2 was written correctly, you don't actually have to do anything here. The test `test_viterbi_is_same_d3_1` will test this.\n",
    "\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(viterbi); # just in case you need to modify it\n",
    "reload(structure_perceptron);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2\n"
     ]
    }
   ],
   "source": [
    "theta_toy_one_inst_classifier,_ = structure_perceptron.estimate_perceptron(toy_data,\n",
    "                                                                features.word_feats,\n",
    "                                                                tagger_base.classifier_tagger,\n",
    "                                                                3,\n",
    "                                                                all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2\n"
     ]
    }
   ],
   "source": [
    "theta_toy_one_inst_viterbi,_ = structure_perceptron.estimate_perceptron(toy_data,\n",
    "                                                                features.word_feats,\n",
    "                                                                viterbi.viterbi_tagger,\n",
    "                                                                3,\n",
    "                                                                all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(theta_toy_one_inst_classifier, theta_toy_one_inst_viterbi)\n",
    "theta_toy_one_inst_classifier == theta_toy_one_inst_viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of using the Viterbi algorithm for structure prediction is that you can use features that look at more than one tag at a time. \n",
    "\n",
    "**Deliverable 3.2** Implement `features.hmm_feats`. This will be very similar to `hmm.hmm_features` from problem set 2, we've only changed some of the constants.\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);\n",
    "reload(structure_perceptron);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['They', 'can', 'fish'], ['PRON', 'AUX', 'VERB']),\n",
       " (['the', 'old', 'man', 'the', 'boat'],\n",
       "  ['DET', 'NOUN', 'VERB', 'DET', 'NOUN'])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('PRON', '--CURR-WORD--', 'They'): 1, ('PRON', '--PREV-TAG--', '--START--'): 1}\n",
      "{('AUX', '--CURR-WORD--', 'can'): 1, ('AUX', '--PREV-TAG--', 'PRON'): 1}\n",
      "{('VERB', '--CURR-WORD--', 'fish'): 1, ('VERB', '--PREV-TAG--', 'AUX'): 1}\n",
      "{('--END--', '--PREV-TAG--', 'VERB'): 1}\n"
     ]
    }
   ],
   "source": [
    "print(features.hmm_feats(toy_data[0][0],'PRON',constants.START_TAG,0))\n",
    "print(features.hmm_feats(toy_data[0][0],'AUX','PRON',1))\n",
    "print(features.hmm_feats(toy_data[0][0],'VERB','AUX',2))\n",
    "print(features.hmm_feats(toy_data[0][0],constants.END_TAG,'VERB',3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 3.3** Evaluate the performance of this structured perceptron on the dev data.\n",
    "\n",
    "This will be slower than the perceptrons that you have trained in the earlier parts of this assignment.\n",
    "\n",
    "(*0.5 points for 4650, 0.25 points for 7650*)\n",
    "\n",
    "This cell takes three minutes to execute on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14\n"
     ]
    }
   ],
   "source": [
    "#English\n",
    "theta_hmm_sp,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.hmm_feats,\n",
    "                                         viterbi.viterbi_tagger,\n",
    "                                         15,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n",
      "0.874700239808\n"
     ]
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               viterbi.viterbi_tagger,\n",
    "                               features.hmm_feats,\n",
    "                               theta_hmm_sp,\n",
    "                               all_tags,\n",
    "                               'sp-hmm.preds')\n",
    "print(dev_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better than many of the fancier feature sets that we tried using the classification-based tagger. \n",
    "\n",
    "That's the power of structured prediction!\n",
    "\n",
    "Now let's try Japanese. This cell takes a little more than two minutes to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14\n"
     ]
    }
   ],
   "source": [
    "#Japanese\n",
    "theta_hmm_sp_ja,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.hmm_feats,\n",
    "                                         viterbi.viterbi_tagger,\n",
    "                                         15,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n",
      "0.806661433217\n"
     ]
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               viterbi.viterbi_tagger,\n",
    "                               features.hmm_feats,\n",
    "                               theta_hmm_sp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'sp-hmm.ja.preds')\n",
    "print(dev_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The improvement for Japanese is much more limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bakeoff #2\n",
    "\n",
    "**Deliverable 3.4** Implement the best features that you can for English and Japanese, this time using structured prediction with viterbi tagging.\n",
    "\n",
    "Make sure to save the output in the following files:\n",
    "\n",
    "- **English dev**: `sp-best.preds`\n",
    "- **English test**: `sp-best-te.preds`\n",
    "- **Japanese dev**: `sp-best.ja.preds`\n",
    "- **Japanese test**: `sp-best-te.ja.preds`\n",
    "\n",
    "Grading:\n",
    "- Full credit (0.5 points) for **89.5%** accuracy on English dev set, half credit (0.25 points) for **88.5%** accuracy.\n",
    "- Full credit (0.5 points) for **91%** accuracy on Japanese dev set, half credit (0.25 points) for **90%** accuracy.\n",
    "- +0.1 for beating my test set score on English\n",
    "- +0.1 for beating my test set score on Japanese\n",
    "- +0.2 for top English test set score in 4650\n",
    "- +0.2 for top English test set score in 7650\n",
    "- +0.2 for top Japanese test set score in 4650\n",
    "- +0.2 for top Japanese test set score in 7650\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Notes\n",
    "Refer back to the Kaggle note under Bakeoff #1 if you need a reminder what to do.\n",
    "If you would like to implement a better tagger such as Conditional Random Fields in order to compete in the competition, you may do that.  If you just want to feature engineer structured perceptron, that is fine.\n",
    "You may *NOT* use outside libraries like Scikit-Learn or TensorFlow if you decide to create an alternate tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n"
     ]
    }
   ],
   "source": [
    "theta_best_sp,theta_best_sp_hist =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.hmm_feats_competitive_en,\n",
    "                                         viterbi.viterbi_tagger,\n",
    "                                         30,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41993"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([val for val in theta_best_sp.values() if val != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n",
      "0.907074340528\n"
     ]
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               viterbi.viterbi_tagger,\n",
    "                               features.hmm_feats_competitive_en,\n",
    "                               theta_best_sp,\n",
    "                               all_tags,\n",
    "                               'sp-best.preds')\n",
    "print(dev_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.TEST_FILE_HIDDEN,\n",
    "                                viterbi.viterbi_tagger,\n",
    "                                features.hmm_feats_competitive_en,\n",
    "                                theta_best_sp,\n",
    "                                all_tags,\n",
    "                                'sp-best-te.preds')\n",
    "\n",
    "# SUBMIT KAGGLE-sp-bakeoff2-en-test.csv to https://kaggle.com/join/gt46507650spenpset3\n",
    "kaggle.kaggle_output(constants.TEST_FILE_HIDDEN,\n",
    "                                viterbi.viterbi_tagger,\n",
    "                                features.hmm_feats_competitive_en,\n",
    "                                theta_best_sp,\n",
    "                                all_tags,\n",
    "                                'KAGGLE-sp-bakeoff2-en-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-cdb3e61b7e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# you can't run this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sp-best-te.preds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Success\\OneDrive\\Documents\\Georgia Tech\\Junior Year\\Spring 2017\\CS 4650\\Problem Set 3\\gtnlplib\\scorer.pyc\u001b[0m in \u001b[0;36mget_confusion\u001b[0;34m(keyfilename, responsefilename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsefilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'"
     ]
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.TEST_FILE,'sp-best-te.preds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41993"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([val for val in theta_best_sp.values() if val != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n"
     ]
    }
   ],
   "source": [
    "theta_best_sp_ja,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.hmm_feats_competitive_ja,\n",
    "                                         viterbi.viterbi_tagger,\n",
    "                                         30,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57046"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features\n",
    "len([val for val in theta_best_sp_ja.values() if val != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n",
      "0.924414040597\n"
     ]
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               viterbi.viterbi_tagger,\n",
    "                               features.hmm_feats_competitive_ja,\n",
    "                               theta_best_sp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'sp-best.ja.preds')\n",
    "print(dev_results)\n",
    "tagger_base.apply_tagging_model(constants.JA_TEST_FILE_HIDDEN,\n",
    "                                viterbi.viterbi_tagger,\n",
    "                                features.hmm_feats_competitive_ja,\n",
    "                                theta_best_sp_ja,\n",
    "                                all_tags_ja,\n",
    "                                'sp-best-te.ja.preds')\n",
    "\n",
    "# SUBMIT KAGGLE-sp-bakeoff2-ja-test.csv to https://kaggle.com/join/gtcs46507650pset3ja\n",
    "kaggle.kaggle_output(constants.JA_TEST_FILE_HIDDEN,\n",
    "                                viterbi.viterbi_tagger,\n",
    "                                features.hmm_feats_competitive_ja,\n",
    "                                theta_best_sp_ja,\n",
    "                                all_tags_ja,\n",
    "                                'KAGGLE-sp-bakeoff2-ja-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/ja-ud-simpler-test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-91a663f88ab4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# you can't run this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJA_TEST_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sp-best-te.ja.preds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Success\\OneDrive\\Documents\\Georgia Tech\\Junior Year\\Spring 2017\\CS 4650\\Problem Set 3\\gtnlplib\\scorer.pyc\u001b[0m in \u001b[0;36mget_confusion\u001b[0;34m(keyfilename, responsefilename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsefilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/ja-ud-simpler-test.conllu'"
     ]
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.JA_TEST_FILE,'sp-best-te.ja.preds'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
